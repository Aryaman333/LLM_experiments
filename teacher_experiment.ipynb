{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import openai\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filepath=r'new_data.json'):\n",
    "    with open(filepath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI()\n",
    "def call_gpt(client, messages, user, model='gpt-4o-mini', format=\"json\",temp=0.7):\n",
    "    if format == \"json\":\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            temperature=temp,\n",
    "            user = user,\n",
    "            logprobs=True\n",
    "        )\n",
    "        response_dict = dict(response.choices[0].message)\n",
    "        logprobs = [token.logprob for token in response.choices[0].logprobs.content]\n",
    "        response_dict[\"perplexity_score\"] = np.exp(-np.mean(logprobs))\n",
    "        if user!=None:\n",
    "            response_dict['user']=user\n",
    "            response_dict['role'] = \"user\"\n",
    "            del response_dict['function_call']\n",
    "            del response_dict['tool_calls']\n",
    "            return response_dict,json.loads(response.choices[0].message.content)\n",
    "        else:\n",
    "            return response_dict, json.loads(response.choices[0].message.content)\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            user = user,\n",
    "            logprobs=True\n",
    "        )\n",
    "        return response_dict,response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different simulations for different eval questions, try different responses. Make student prompts more random and simple and less restrictive. Only specify in prompt to answer an eval question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teacher class containing all teacher prompts. General response prompts used for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher:\n",
    "    def __init__(self,personas) :\n",
    "        self.personas=personas\n",
    "\n",
    "    def lecture(self,actions):\n",
    "        schema = {\"lecture\":\"lecture\"}\n",
    "        messages = {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"\"\"\n",
    "                    You are a high school teacher who has to teach students having different ethnic diversities and personality traits. \n",
    "                    The profiles of the students is given in {self.personas}. Some student actions classified into good and bad actions is given in: {actions}.\n",
    "                    Correct the students if a bad action is performed and praise them for performing a good action. \n",
    "                    The more times a bad action is repeated the more strict the reply should be.  \n",
    "                    The topic of today's class is 'Climate Change and Global Warming'. \n",
    "                    You need to create a small lecture on the topic. Take into consideration the backgrounds of the students but do not specifically address any students.\n",
    "                    The lecture should explain the topic well and should engage different kinds of students. \n",
    "                    The summary should be human-readable.\n",
    "                    Strictly reply in JSON format which follows the schema: {schema}\n",
    "                \"\"\"\n",
    "            }\n",
    "        return messages\n",
    "\n",
    "    # def lecture(self):\n",
    "    #     schema = {\"summary\":\"summary\", \"questions\":{\"Q1\":\"Question 1\", \"Q2\":\"Question 2\"}}\n",
    "    #     messages = {\n",
    "    #             \"role\": \"system\", \n",
    "    #             \"content\": f\"\"\"\n",
    "    #                 You are a high school teacher who has to teach students from different ethnic diversities. \n",
    "    #                 The ethnic profiles of the students is given in {self.personas}.\n",
    "    #                 Your abilities as a teacher are giving lectures, asking questions specific to a student's background and answer questions asked by students.\n",
    "    #                 The topic of today's class is 'Climate Change and Global Warming'. \n",
    "    #                 You need to create a small lecture on the topic. Take into consideration the backgrounds of the students but do not specifically address any students.\n",
    "    #                 The lecture should explain the topic well. \n",
    "    #                 Reply by giving a summary of the lecture and a set of questions to test the knowledge of the students.\n",
    "    #                 Consider the student profiles while crafting the questions but they should be answerable by all students. \n",
    "    #                 The questions can be scenario based.\n",
    "    #                 Strictly reply with a single summary and two questions. \n",
    "    #                 The summary and questions should be human-readable.\n",
    "    #                 Strictly reply in JSON format which follows the schema: {schema}\n",
    "    #             \"\"\"\n",
    "    #         }\n",
    "        \n",
    "    #     # response_msg,response = call_gpt(client, messages,user=None, format=\"json\") \n",
    "    #     return messages\n",
    "    def general_response(self):\n",
    "        messages = {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"\"\"\n",
    "                    You need to respond to the students who have certain comments/questions about the lecture. \n",
    "                    The response should either be a command, request, question, correction or general statement depending on the students response.\n",
    "                    You are allowed to b have negative comments if the student is taking conversations off-topic or distracting the class. \n",
    "                    Penalize behaviour that is not common by replying in a negative manner.\n",
    "                    Highly consider the students background information while responding.   \n",
    "                    The response should be concise and human-readable.\n",
    "                    Strictly reply in JSON format which follows the schema\n",
    "                \"\"\"\n",
    "            }\n",
    "        return messages\n",
    "    def answer(self,questions,persona):\n",
    "        schema = {\"A1\":\"answer 1\", \"A2\":\"answer 2\"}\n",
    "        messages = {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"\"\"\n",
    "                    The student:{persona} has now answered your questions and asked further questions given in {questions}.\n",
    "                    Answer these questions very concisely by strictly considering their background profile.\n",
    "                    Strictly answer in two sentences or less.\n",
    "                    The answer should be human-readable.\n",
    "                    Strictly reply in JSON format which follows the schema: {schema}\n",
    "                \"\"\"\n",
    "            }\n",
    "        # response_msg,response = call_gpt(client, messages,user=None, format=\"json\") \n",
    "        return messages\n",
    "    \n",
    "    \n",
    "    def evaluate(self,questions):\n",
    "        schema = {\"Question 1\":{\"question\":\"question\",\"dialogues\":\"dialogues by students that are relevant for answering the question.\",\"answer\":\"answer\",\"learnings\":\"What did you learn from the incident\"},}\n",
    "        messages ={\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"\"\"\n",
    "                    The students have now given a summary of their learnings and feedback for the lecture.\n",
    "                    Now you have to assess your teaching experience based on the past conversations with the students by answering the questions in {questions}.\n",
    "                    Answer the questions strictly based on how the students responded during the lecture, their learnings and their feedback. \n",
    "                    The answer should highlight dialogues from different students relevant to the question, how you handled the situation and what you learnt.\n",
    "                    Answer each question very concisely.\n",
    "                    Strictly Reply in JSON format: {schema}.                \n",
    "                \"\"\"\n",
    "            }\n",
    "        return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline evaluation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(questions):\n",
    "    schema = [{\"Question 1\":{\"question\":\"question\",\"answer\":\"answer\"},}]\n",
    "    messages = [{\n",
    "            \"role\": \"system\", \n",
    "            \"content\": f\"\"\"\n",
    "                You are a high school teacher who has to teach students having varied ethnic diversities and personality traits.\n",
    "                You have to answer these questions: {questions} to demonstrate your experience as a teacher.\n",
    "                The answers should be concise and human-readable. \n",
    "                Strictly Reply in JSON format with schema: {schema}.\n",
    "            \"\"\"\n",
    "        }]\n",
    "    \n",
    "    response_msg,response = call_gpt(client, messages,user=None, format=\"json\",temp=0.0) \n",
    "    return response_msg,response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student class containing all student prompts. General response and student summary prompts used currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student():\n",
    "    def __init__(self,persona, user_id):\n",
    "        self.persona=persona\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def general_response(self,persona,conversation):\n",
    "        messages = [{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"\"\"\n",
    "                    The past interraction in the lecture is given in {conversation}.\n",
    "                    You need to respond to the teacher's comments/question. \n",
    "                    Highly consider your background profile given in {persona}, while responding.\n",
    "                    Your response should strictly be one of the actions mentioned in your profile.  \n",
    "                    The response should be concise and human-readable.\n",
    "                \"\"\"\n",
    "            }]\n",
    "        response_msg,response = call_gpt(client, messages,user=self.user_id, format=\"json\") \n",
    "        return response_msg, response\n",
    "    \n",
    "    def student_QA(self,summary,questions):\n",
    "        schema = {\"Answers\":{\"A1\":\"answer 1\", \"A2\":\"answer 2\"}, \"Questions\":{\"Q1\" : \"question 1\",\"Q2\" : \"question 2\"}}\n",
    "        messages = [ \n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"\"\"\n",
    "                        You are a high school student whose profile is given by {self.persona}. \n",
    "                        The topic of today's class is 'Climate Change and Global Warming'.\n",
    "                        The teacher will provide the summary of the lecture and some questions for you to answer.\n",
    "                        You need to answer the questions and ask further questions strictly according to the background information given in your profile. \n",
    "                        The answers and new questions can be scenario based or a personal experience unique to your background. \n",
    "                        Strictly ask two or lesser questions.\n",
    "                        The answers and the questions should be very concise and human-readable.\n",
    "                        Strictly reply in JSON format which follows the schema: {schema}\n",
    "                    \"\"\"\n",
    "                },\n",
    "                { \"role\": \"user\", \"content\": f\"This is the summary of the lecture:{summary}\"},\n",
    "                { \"role\": \"user\", \"content\": f\"These are the questions you need to answer:{questions}\"}\n",
    "        ]\n",
    "        response_msg,response = call_gpt(client, messages,user=self.user_id, format=\"json\") \n",
    "        return response_msg, response\n",
    "    \n",
    "    def answer(self,summary,questions):\n",
    "        schema =  {\"A1\":\"answer 1\", \"A2\":\"answer 2\"}\n",
    "        messages = [ \n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"\"\"\n",
    "                        You are a high school student whose profile is given by {self.persona}. \n",
    "                        The topic of today's class is 'Climate Change and Global Warming'.\n",
    "                        The teacher will provide the summary of the lecture and some questions for you to answer.\n",
    "                        You need to answer the questions these questions by strictly considering your background details. \n",
    "                        The answers can be scenario based on a personal experience unique to your background. \n",
    "                        The answers should be very concise and human-readable.\n",
    "                        Strictly reply in JSON format which follows the schema: {schema}\n",
    "                    \"\"\"\n",
    "                },\n",
    "                { \"role\": \"user\", \"content\": f\"This is the summary of the lecture:{summary}\"},\n",
    "                { \"role\": \"user\", \"content\": f\"These are the questions you need to answer:{questions}\"}\n",
    "        ]\n",
    "        response_msg,response = call_gpt(client, messages,user=self.user_id, format=\"json\") \n",
    "        return response_msg, response\n",
    "    \n",
    "    def student_summ(self,persona,conversation):\n",
    "        schema = {\"feedback\":\"student feedback\"}\n",
    "        messages = [ \n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"\"\"\n",
    "                        You are a high school student whose profile is given by {persona}. \n",
    "                        The topic of today's class is 'Climate Change and Global Warming'.\n",
    "                        The past interraction in the class is given in {conversation}.\n",
    "                        You need to give feedback to the teacher strictly based on your past interraction with the teacher and your background details.\n",
    "                        The feedback can include suggestions, what you liked?, what you disliked?, were your queries answered by the teacher?, what improvements should you make as a student?, what improvements the teacher should make?, etc. \n",
    "                        The feedback should strictly consider your profile details and past interraction with the teacher.\n",
    "                        Strictly reply in JSON format which follows the schema: {schema}\n",
    "                    \"\"\"\n",
    "                }\n",
    "        ]\n",
    "        response_msg,response = call_gpt(client, messages,user=self.user_id, format=\"json\") \n",
    "        return response_msg, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions. Not used currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lecture(lecture):\n",
    "    split = lecture.split(\"[\")\n",
    "    summary=split[0]\n",
    "    questions = split[1:]\n",
    "    return summary,questions\n",
    "\n",
    "def preprocess_student_qa(student_qa):\n",
    "    split = student_qa.split(\",[\")\n",
    "    answers=split[0]\n",
    "    questions = split[1:]\n",
    "    return questions,answers\n",
    "\n",
    "def preprocess_student_qa1(student_qa):\n",
    "    split = student_qa.split(\"Q1\")\n",
    "    answers=split[0]\n",
    "    questions = split[1:]\n",
    "    return questions,answers\n",
    "\n",
    "def questions_dict(questions):\n",
    "    questions_list = []\n",
    "    for i,question in enumerate(questions):\n",
    "        temp = {}\n",
    "        temp['user'] = \"student {id}\".format(id=i+1)\n",
    "        temp['questions'] = question\n",
    "        questions_list.append(temp)\n",
    "    return questions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = json.load(open(r'data\\personas.json'))\n",
    "questions_eval = json.load(open(r'data\\questions.json'))\n",
    "actions = json.load(open(r'data\\Actions_cat.json'))\n",
    "# content = json.load(open(r'C:\\Projects\\LLM_experiments\\content.json'))\n",
    "\n",
    "teacher = Teacher(personas)\n",
    "student_1 = Student(personas[0],\"Amina Hussein\")\n",
    "student_2 = Student(personas[1], \"Rajesh Kumar\")\n",
    "student_3 = Student(personas[2],\"Svetlana Petrov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Svetlana Petrov',\n",
       " 'user': 'student 3',\n",
       " 'Origin': 'Moscow, Russia',\n",
       " 'Background': 'Svetlina is a creative and imaginative person. She likes to joke around. She is a part of various clubs. She presents solutions to problems in a very creative way.',\n",
       " 'Actions': {'Action 1': 'Make a joke.'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personas[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample simulation: Lecture -> General student responses -> General teacher responses -> student summary and feedback -> evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19976\\540994345.py:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  with open('data\\Conversations\\conv.txt', 'w') as f:\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "with open('data\\Conversations\\conv.txt', 'w') as f:\n",
    "    # Teacher delivers lecture\n",
    "    messages.append(teacher.lecture(actions))\n",
    "    res,lecture = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res)\n",
    "    f.write(\"Teacher:\\t\"+str(lecture)+\"\\n\")\n",
    "\n",
    "    # Student 1 general response and teachers response to the student\n",
    "    messages.append(teacher.general_response())\n",
    "    res_msg,res = student_1.general_response(personas[0],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_1: \\t\"+ str(res)+\"\\n\")\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Teacher:\\t\"+str(res)+\"\\n\")\n",
    "\n",
    "    # Student 2 general response(object) and teachers response to the student\n",
    "    res_msg,res = student_2.general_response(personas[1],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_2: \\t\"+ str(res)+\"\\n\")\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Teacher:\\t\"+str(res)+\"\\n\")\n",
    "\n",
    "    # Student 2 repeated objection and teachers response to the student\n",
    "    res_msg,res = student_2.general_response(personas[1],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_2: \\t\"+ str(res)+\"\\n\")\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Teacher:\\t\"+str(res)+\"\\n\")\n",
    "\n",
    "    # Student 3 general response(joke) and teachers response to the student\n",
    "    res_msg,res = student_3.general_response(personas[2],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_3: \\t\"+ str(res)+\"\\n\")\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Teacher:\\t\"+str(res)+\"\\n\")\n",
    "\n",
    "     # Student 2 repeated joke and teachers response to the student\n",
    "    res_msg,res = student_3.general_response(personas[2],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_3: \\t\"+ str(res)+\"\\n\")\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.7)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Teacher:\\t\"+str(res)+\"\\n\")\n",
    "\n",
    "    # Students summary and feedback\n",
    "    res_msg,res = student_1.student_summ(personas[0],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_1: \\t\"+ str(res)+\"\\n\")\n",
    "\n",
    "    res_msg,res = student_2.student_summ(personas[1],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_2: \\t\"+ str(res)+\"\\n\")\n",
    "\n",
    "    res_msg,res = student_3.student_summ(personas[2],messages)\n",
    "    messages.append(res_msg)\n",
    "    f.write(\"Student_3: \\t\"+ str(res)+\"\\n\")\n",
    "\n",
    "    # Teacher evaluate\n",
    "    messages.append(teacher.evaluate([questions_eval[\"Question 2\"],questions_eval[\"Question 15\"],questions_eval[\"Question 7\"],questions_eval[\"Question 10\"],questions_eval[\"Question 5\"],questions_eval[\"Question 8\"]]))\n",
    "    res_msg,res = call_gpt(client,messages=messages,user=None, format=\"json\",temp=0.0)\n",
    "    messages.append(res_msg)\n",
    "    messages.append(res)\n",
    "    f.write(\"Teacher: \\t\"+ str(res)+\"\\n\")\n",
    "    \n",
    "    f.close()\n",
    "save_json(messages,r\"C:\\Projects\\LLM_experiments\\data\\Conversations\\conversations_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_eval_baseline = json.load(open(r'data\\questions_baseline.json'))\n",
    "res_msg,res = evaluate_baseline([questions_eval[\"Question 2\"],questions_eval[\"Question 15\"],questions_eval[\"Question 7\"],questions_eval[\"Question 10\"],questions_eval[\"Question 5\"],questions_eval[\"Question 8\"]])\n",
    "save_json(res,r\"C:\\Projects\\LLM_experiments\\data\\Conversations\\conversations_base_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Teacher' object has no attribute 'evaluate_baseline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m questions_eval_baseline \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mquestions_baseline.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m res_msg,res \u001b[38;5;241m=\u001b[39m \u001b[43mteacher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_baseline\u001b[49m(questions_eval_baseline)\n\u001b[0;32m      3\u001b[0m save_json(res,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLM_experiments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mConversations\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconversations_base.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Teacher' object has no attribute 'evaluate_baseline'"
     ]
    }
   ],
   "source": [
    "questions_eval_baseline = json.load(open(r'data\\questions_baseline.json'))\n",
    "res_msg,res = evaluate_baseline(questions_eval_baseline)\n",
    "save_json(res,r\"C:\\Projects\\LLM_experiments\\data\\Conversations\\conversations_base.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = questions_dict([qa_1['Questions'],qa_2['Questions'],qa_3['Questions']])\n",
    "\n",
    "    # res_msg, res = teacher.answer(conversations,questions)\n",
    "    # conversations.append([res_msg])\n",
    "    # f.write(\"Teacher: \\t\"+ str(res))\n",
    "\n",
    "    # f.write(\"Student_3: \\t\"+ str(qa))\n",
    "    # print(student_1_qa)\n",
    "    # questions_1,answers_1 = preprocess_student_qa1(student_1_qa)\n",
    "    # f.write(\"Student_1: \\t Here are the answers to your questions\\t\" + str(answers_1) +\"I have these further questions:\\t\"+str(questions_1)+ '\\n\\n')\n",
    "    # student_2_qa = student_2.student_QA(summ,questions)\n",
    "    # questions_2,answers_2 = preprocess_student_qa1(student_2_qa)\n",
    "    # f.write(\"Rajesh: \\t Here are the answers to your questions\\t\" + str(answers_2) +\"I have these further questions:\\t\"+str(questions_2)+ '\\n\\n')\n",
    "    # student_3_qa = student_3.student_QA(summ,questions)\n",
    "    # print(student_3_qa)\n",
    "    # questions_3,answers_3 = preprocess_student_qa1(student_3_qa)\n",
    "    # f.write(\"Svetlana: \\t Here are the answers to your questions\\t\" + str(answers_3) +\"I have these further questions:\\t\"+str(questions_3)+ '\\n\\n')\n",
    "    # teacher_answers_1 = teacher.answer(f,questions_1,personas[0])\n",
    "    # f.write(\"Teacher: \\t Here are the answers to your questions \" + str(teacher_answers_1) + '\\n\\n')\n",
    "    # teacher_answers_2 = teacher.answer(f,questions_2,personas[1])\n",
    "    # f.write(\"Teacher: \\t Here are the answers to your questions \" + str(teacher_answers_2) + '\\n\\n')\n",
    "    # teacher_answers_3 = teacher.answer(f,questions_3,personas[2])\n",
    "    # f.write(\"Teacher: \\t Here are the answers to your questions \" + str(teacher_answers_3) + '\\n\\n')\n",
    "    # feedback_1 = student_1.student_summ(f,personas[0])\n",
    "    # feedback_1,summary_1 = preprocess_student_qa(feedback_1)\n",
    "    # f.write(\"Amina: \\t This is the summary of my learnings \" + str(summary_1) + \"This is my feedback for the lecture:\"+str(feedback_1)+'\\n\\n')\n",
    "    # feedback_2 = student_2.student_summ(f,personas[1])\n",
    "    # feedback_2,summary_2 = preprocess_student_qa(feedback_2)\n",
    "    # f.write(\"Rajesh: \\t This is the summary of my learnings \" + str(summary_2) + \"This is my feedback for the lecture:\"+str(feedback_2)+'\\n\\n')\n",
    "    # feedback_3 = student_3.student_summ(f,personas[2])\n",
    "    # feedback_3,summary_3 = preprocess_student_qa(feedback_3)\n",
    "    # f.write(\"Svetlana: \\t This is the summary of my learnings \" + str(summary_3) + \"This is my feedback for the lecture:\"+str(feedback_3)+'\\n\\n')\n",
    "    # evaluation = teacher.evaluate(f)\n",
    "    # f.write(\"Teacher:\\tAssessment report for each student: \" + str(evaluation) +'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
